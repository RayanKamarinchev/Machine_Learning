{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMPepXstigrSnesjPy//Ag8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":11,"metadata":{"id":"m2B3vSfxtoUK","executionInfo":{"status":"ok","timestamp":1672299082247,"user_tz":-120,"elapsed":9393,"user":{"displayName":"Rayan DK","userId":"05852992590477517052"}}},"outputs":[],"source":["!pip install -q transformers datasets\n","!pip install -q timm"]},{"cell_type":"code","source":["from PIL import Image\n","import requests\n","\n","from transformers import DetrImageProcessor, DetrForObjectDetection\n","import torch\n","from PIL import Image\n","import requests\n","\n","url = \"http://images.cocodataset.org/val2017/000000039769.jpg\"\n","image = Image.open(requests.get(url, stream=True).raw)\n","\n","processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n","model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n","\n","inputs = processor(images=image, return_tensors=\"pt\")\n","outputs = model(**inputs)\n","\n","# convert outputs (bounding boxes and class logits) to COCO API\n","# let's only keep detections with score > 0.9\n","target_sizes = torch.tensor([image.size[::-1]])\n","results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n","\n","for score, label, box in zip(results[\"scores\"], results[\"labels\"], results[\"boxes\"]):\n","    box = [round(i, 2) for i in box.tolist()]\n","    print(\n","            f\"Detected {model.config.id2label[label.item()]} with confidence \"\n","            f\"{round(score.item(), 3)} at location {box}\"\n","    )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nVc2wwYvw6l","executionInfo":{"status":"ok","timestamp":1672299112621,"user_tz":-120,"elapsed":11938,"user":{"displayName":"Rayan DK","userId":"05852992590477517052"}},"outputId":"205a8d87-d37b-4f16-f2ca-87958eb3e020"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.8/dist-packages/transformers/models/detr/image_processing_detr.py:773: FutureWarning: The `max_size` parameter is deprecated and will be removed in v4.26. Please specify in `size['longest_edge'] instead`.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["Detected remote with confidence 0.998 at location [40.16, 70.81, 175.55, 117.98]\n","Detected remote with confidence 0.996 at location [333.24, 72.55, 368.33, 187.66]\n","Detected couch with confidence 0.995 at location [-0.02, 1.15, 639.73, 473.76]\n","Detected cat with confidence 0.999 at location [13.24, 52.05, 314.02, 470.93]\n","Detected cat with confidence 0.999 at location [345.4, 23.85, 640.37, 368.72]\n"]}]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# colors for visualization\n","COLORS = [[0.000, 0.447, 0.741], [0.850, 0.325, 0.098], [0.929, 0.694, 0.125], [0.494, 0.184, 0.556], [0.466, 0.674, 0.188]]\n","\n","import io\n","\n","def fig2img(fig):\n","    buf = io.BytesIO()\n","    fig.savefig(buf)\n","    buf.seek(0)\n","    img = Image.open(buf)\n","    return img\n","\n","def plot_results(image, results):\n","    plt.figure(figsize=(16, 10))\n","    plt.imshow(image)\n","    ax = plt.gca()\n","    colors = COLORS * 100\n","    for box, label, prob, color in zip(results[\"boxes\"], results[\"labels\"], results[\"scores\"], colors):\n","        xmin, xmax, ymin, ymax = box[0].item(), box[2].item(), box[1].item(), box[3].item()\n","        ax.add_patch(plt.Rectangle((xmin, ymin), xmax - xmin, ymax - ymin,\n","                                   fill=False, color=color, linewidth=3))\n","        text = f'{model.config.id2label[label.item()]}: {prob:0.2f}'\n","        ax.text(xmin, ymin, text, fontsize=15,\n","                bbox=dict(facecolor='yellow', alpha=0.5))\n","    ax.axis(\"off\")\n","    return fig2img(plt.gcf())\n","\n","def predict(input_img):\n","    processor = DetrImageProcessor.from_pretrained(\"facebook/detr-resnet-50\")\n","    model = DetrForObjectDetection.from_pretrained(\"facebook/detr-resnet-50\")\n","    inputs = processor(images=input_img, return_tensors=\"pt\")\n","    outputs = model(**inputs)\n","\n","    target_sizes = torch.tensor([input_img.size[::-1]])\n","    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]\n","    return plot_results(input_img, results)"],"metadata":{"id":"-GH4E7gDwe_p","executionInfo":{"status":"ok","timestamp":1672305221522,"user_tz":-120,"elapsed":5,"user":{"displayName":"Rayan DK","userId":"05852992590477517052"}}},"execution_count":114,"outputs":[]},{"cell_type":"code","source":["#!pip install gradio\n","import gradio as gr\n","\n","demo = gr.Interface(fn=predict,\n","                    inputs=gr.Image(type=\"pil\"),\n","                    outputs=\"image\")\n","demo.launch()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":651},"id":"wRamaigC2IQM","executionInfo":{"status":"ok","timestamp":1672305225035,"user_tz":-120,"elapsed":2157,"user":{"displayName":"Rayan DK","userId":"05852992590477517052"}},"outputId":"941fb4a8-f387-4537-d842-f6a114ae5560"},"execution_count":115,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Thanks for being a Gradio user! If you have questions or feedback, please join our Discord server and chat with us: https://discord.gg/feTf9x3ZSB\n","Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n","Note: opening Chrome Inspector may crash demo inside Colab notebooks.\n","\n","To create a public link, set `share=True` in `launch()`.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["(async (port, path, width, height, cache, element) => {\n","                        if (!google.colab.kernel.accessAllowed && !cache) {\n","                            return;\n","                        }\n","                        element.appendChild(document.createTextNode(''));\n","                        const url = await google.colab.kernel.proxyPort(port, {cache});\n","\n","                        const external_link = document.createElement('div');\n","                        external_link.innerHTML = `\n","                            <div style=\"font-family: monospace; margin-bottom: 0.5rem\">\n","                                Running on <a href=${new URL(path, url).toString()} target=\"_blank\">\n","                                    https://localhost:${port}${path}\n","                                </a>\n","                            </div>\n","                        `;\n","                        element.appendChild(external_link);\n","\n","                        const iframe = document.createElement('iframe');\n","                        iframe.src = new URL(path, url).toString();\n","                        iframe.height = height;\n","                        iframe.allow = \"autoplay; camera; microphone; clipboard-read; clipboard-write;\"\n","                        iframe.width = width;\n","                        iframe.style.border = 0;\n","                        element.appendChild(iframe);\n","                    })(7884, \"/\", \"100%\", 500, false, window.element)"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":[]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["predict(image)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1G2aTRBY8Gra4jQf51rvyMoN-HKq96F9e"},"id":"S6GxvpFB_y8b","executionInfo":{"status":"ok","timestamp":1672304058401,"user_tz":-120,"elapsed":8963,"user":{"displayName":"Rayan DK","userId":"05852992590477517052"}},"outputId":"6bc184ad-fd3a-48a1-b6c1-89d95212fa63"},"execution_count":87,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}